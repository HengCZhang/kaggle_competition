{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Jane Street Real-Time Market Data Forecasting**\n",
    "\n",
    "Jane Street Group在kaggle平台发布了数据挖掘算法竞赛—Jane Street Real-Time Market Data Forecasting，其提供多个交易品种的真实交易历史数据，要求参赛者充分结合数据特征分布及机器学习技术进行建模，以应对交易数据中存在的厚尾效应、非平稳变化以及市场行为的突变效应等，进而提升指定交易品种的特征变化及交易胜率。\n",
    "\n",
    "数据部分包括训练数据集、测试数据集、滞后数据集、特征数据集、交易指标集、预测结果集等6个部分，均采用parquet或csv格式，具体描述如下：\n",
    "\n",
    "（1）训练数据集——包括date_id、time_id、symbol_id、weight、feature_i、responder_i等字段，date_id和time_id提供数据时间结构，symbol_id为交易品种标识，weight用于计算评分函数的权重，feature_i(i=0,1,...,78)表示79个数据特征，responder_i(i=0,1,...,8)表示9个交易指标。\n",
    "\n",
    "（2）测试数据集——包括date_id、time_id、symbol_id、weight、is_scored、feature_i等字段，其中is_scored表示样本是否参与评分函数计算，其他参数与训练数据中含义相同。\n",
    "\n",
    "（3）滞后数据集——字段与训练数据集保持一致，其内容为date_id滞后一天的真实交易数据。\n",
    "\n",
    "（4）数据特征集——表征feature_i(i=0,1,...,78)与tag_i(i=0,1,...,16)之间的布尔关系。\n",
    "\n",
    "（5）交易指标集——表征responder_i(i=0,1,...,8)与tag_i(i=0,1,...,4)之间的布尔关系。\n",
    "\n",
    "（6）预测结果集——表征预测交易指标responder_6的结果输出格式，预测精度利用拟合优度指标进行评估。\n",
    "\n",
    "**解题思路**：首先对原始数据集进行数据探索及预处理，分析（4）和（5）内容表征的含义并完成数据对齐；其次探索数据分布关系构造新生特征，根据特征重要性和相关系数法优选数据特征库；再次选取向量自回归、高斯过程回归、随机森林、梯度提升树、xgboost、lightgbm、多层感知机、LSTM、RNN共十种机器学习算法对交易数据特征进行建模分析，并保存优选的数据模型；最后对测试数据进行特征构建，并加载优选数据模型进行预测存档。\n",
    "\n",
    "**问题补充**：在实际编码过程中，针对庞大数据集的处理操作容易导致内存溢出问题。因此，考虑针对每一个交易品种独立训练数据模型，在测试过程中对于已知交易品种调用对应模型进行预测，对于未知交易品种则遍历调用模型库进行均值预测。"
   ],
   "id": "337b3a8e95dff39e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 导入三方库\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import traceback\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 设置DataFrame数据展示规格\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# 设置Plot图形中文字体规格\n",
    "matplotlib.rcParams[\"font.family\"] = \"SimHei\"\n",
    "matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "c9a7bb8b9f207ad2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 定义全局参数[孤立森林估计器数目，Z-score检测倍数，单行子图数目，交易品种标识序列，交易品种日交易点数，交易品种模型袋，预测交易指标，数据特征列，源数据文件目录，结果数据文件目录，数据文件字典]\n",
    "global_params = {\n",
    "    \"max_Iso_estimators\": 200,\n",
    "    \"z_score_threshold\": 3,\n",
    "    \"subplot_col_num\": 3,\n",
    "    \"symbol_ids\": set(),\n",
    "    \"symbol_day_sample\": dict(),\n",
    "    \"symbol_ids_model_bag\": dict(),\n",
    "    \"predict_responder\": \"responder_6\",\n",
    "    \"data_result_file1\": \"data_exploring_result.xlsx\",\n",
    "    \"root_dir\": \"D:/Kaggle_competitions/Real_time_market_forecasting/data\",\n",
    "    \"result_dir\": \"D:/Kaggle_competitions/Real_time_market_forecasting/result\",\n",
    "    # \"root_dir\": \"/kaggle/input/jane-street-real-time-market-data-forecasting\",\n",
    "    # \"result_dir\": \"/kaggle/working/jane-street-real-time-market-data-forecasting\",\n",
    "    \"data_files_dictionary\": {\"training\":[], \"testing\":[], \"lagging\":[]}\n",
    "}"
   ],
   "id": "12e4771b4c0fb9ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 校验数据文件目录\n",
    "def init_checking():\n",
    "    try:\n",
    "        if not os.path.exists(global_params[\"root_dir\"]):\n",
    "            raise Exception(\"数据源文件目录不存在！\")\n",
    "        if not os.path.exists(global_params[\"result_dir\"]):\n",
    "            print(\"数据存储目录不存在，正在创建数据存储目录...\")\n",
    "            os.mkdir(global_params[\"result_dir\"])\n",
    "            if not os.path.exists(global_params[\"result_dir\"]):\n",
    "                raise ValueError(\"数据存储目录无法创建!\")\n",
    "            else:\n",
    "                print(\"数据存储目录创建成功！\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        if os.path.exists(global_params[\"root_dir\"]) and os.path.exists(global_params[\"result_dir\"]):\n",
    "            print(\"数据源文件目录和数据存储目录正常,开始数据分析建模任务...\")\n",
    "        else:\n",
    "            print(\"数据源文件目录或数据存储目录异常常,请核查源数据文件...\")"
   ],
   "id": "e65ae3248e8e48b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 归集源文件信息\n",
    "def data_file_gathering():\n",
    "    \"\"\"\n",
    "    源文件信息归集\n",
    "    :return: 无\n",
    "    \"\"\"\n",
    "    # 归集数据文件\n",
    "    training_data_files, testing_data_files, lagging_data_files = [], [], []\n",
    "    training_data_dir = os.path.join(global_params[\"root_dir\"], \"train.parquet\")\n",
    "    testing_data_dir = os.path.join(global_params[\"root_dir\"], \"test.parquet\")\n",
    "    lagging_data_dir = os.path.join(global_params[\"root_dir\"], \"lags.parquet\")\n",
    "    for root, dirs, files in os.walk(training_data_dir):\n",
    "        training_data_files.extend([os.path.join(root, file) for file in files])\n",
    "    for root, dirs, files in os.walk(testing_data_dir):\n",
    "        testing_data_files.extend([os.path.join(root, file) for file in files])\n",
    "    for root, dirs, files in os.walk(lagging_data_dir):\n",
    "        lagging_data_files.extend([os.path.join(root, file) for file in files])\n",
    "    global_params[\"data_files_dictionary\"][\"training\"] = training_data_files\n",
    "    global_params[\"data_files_dictionary\"][\"testing\"] = testing_data_files\n",
    "    global_params[\"data_files_dictionary\"][\"lagging\"] = lagging_data_files\n",
    "    # 归集品种信息\n",
    "    symbol_ids = set()\n",
    "    for data_file in global_params[\"data_files_dictionary\"][\"testing\"]:\n",
    "        current_symbol_ids = pl.read_parquet(data_file)[\"symbol_id\"].unique()\n",
    "        symbol_ids.update(set(current_symbol_ids))\n",
    "    global_params[\"symbol_ids\"] = sorted(symbol_ids)\n",
    "    global_params[\"symbol_day_sample\"] = {symbol_id: 0 for symbol_id in global_params[\"symbol_ids\"]}\n",
    "    global_params[\"symbol_ids_model_bag\"] = {symbol_id: [] for symbol_id in global_params[\"symbol_ids\"]}"
   ],
   "id": "5c55975468e0e84f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 抽取训练数据\n",
    "def data_extracting(symbol_id: int=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    根据交易品种ID抽取训练数据集\n",
    "    :param symbol_id: 交易品种ID\n",
    "    :return: 交易品种ID的训练数据集\n",
    "    \"\"\"\n",
    "    if symbol_id is None:\n",
    "        raise ValueError(\"symbol_id参数不能为空！\")\n",
    "    symbol_training_data, sub_block_data_list = pl.DataFrame(), []\n",
    "    for training_data_file in global_params[\"data_files_dictionary\"][\"training\"]:\n",
    "        sub_block_data = pl.read_parquet(training_data_file)\n",
    "        sub_block_data = sub_block_data.filter(sub_block_data[\"symbol_id\"] == symbol_id) if symbol_id is not None else sub_block_data\n",
    "        sub_block_data_list.append(sub_block_data)\n",
    "    symbol_training_data = pl.concat(sub_block_data_list).unique().sort(by=[\"date_id\", \"time_id\"])\n",
    "    global_params[\"symbol_day_sample\"][symbol_id] = symbol_training_data[\"time_id\"].max() + 1\n",
    "    \n",
    "    return symbol_training_data"
   ],
   "id": "ef832df49da758e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 数据缺失率计算\n",
    "def missing_ratio_computing(source_data: pl.DataFrame=None, data_type: str=\"training\", missing_phase: int=0, symbol_id: int=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    计算数据缺失率\n",
    "    :param source_data: 原始数据\n",
    "    :param data_type: 数据类型\n",
    "    :param missing_phase: 数据截断\n",
    "    :param symbol_id: 交易品种ID\n",
    "    :return: 数据缺失率计算结果\n",
    "    \"\"\"\n",
    "    data_rows, missing_ratio_data = source_data.shape[0], {}\n",
    "    for col in source_data:\n",
    "        if col.dtype in [pl.Int64, pl.Float64, pl.Int32, pl.Float32]:\n",
    "            missing_ratio_data[col.name] = (col.is_nan() | col.is_null()).sum() / data_rows\n",
    "        else:\n",
    "            missing_ratio_data[col.name] = col.is_null().sum() / data_rows\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt_name = f\"{symbol_id if symbol_id is not None else ''}{'-原始' if missing_phase==1 else '-截断' if missing_phase==2  else '-标记' if missing_phase==3 else ''}{'训练' if data_type=='training' else '测试'}数据特征缺失率\"\n",
    "    sns.barplot(x=source_data.columns, y=list(missing_ratio_data.values()), color=\"red\", alpha=0.8, edgecolor=\"black\", linewidth=0.5)\n",
    "    plt.title(plt_name, fontsize=16)\n",
    "    plt.xticks(rotation=90, fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.xlabel(\"数据特征名称\", fontsize=12)\n",
    "    plt.ylabel(\"数据特征缺失率\", fontsize=12)\n",
    "    plt_path = os.path.join(global_params[\"result_dir\"], f\"{plt_name}.png\")\n",
    "    plt.savefig(plt_path)\n",
    "    plt.show()\n",
    "    \n",
    "    return pl.DataFrame(data=missing_ratio_data)"
   ],
   "id": "23ee0e9a5b620d5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 相关特征提取\n",
    "def correlation_factor_extracting(source_data: pl.DataFrame=None, max_corr_param: float=0.8) -> list:\n",
    "    \"\"\"\n",
    "    构建相关性矩阵并提取强相关特征\n",
    "    :param source_data: 特征数据\n",
    "    :param max_corr_param: 最大相关系数\n",
    "    :return: 混淆矩阵,强相关特征序列\n",
    "    \"\"\"\n",
    "    correlation_matrix = source_data.corr()\n",
    "    feature_names_series, is_stronger_correlation_tag = pl.Series(correlation_matrix.columns), pl.Series()\n",
    "    while True:\n",
    "        is_stronger_correlation_tag = correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).abs())[global_params[\"predict_responder\"]] > max_corr_param\n",
    "        if is_stronger_correlation_tag.sum() >= 9:\n",
    "            break\n",
    "        else:\n",
    "            max_corr_param -= 0.05\n",
    "    stronger_correlation_factor = feature_names_series.filter(is_stronger_correlation_tag).to_list()\n",
    "    \n",
    "    return [correlation_matrix, stronger_correlation_factor]"
   ],
   "id": "85d89b59d9714439",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 数据关联探索\n",
    "def correlation_analyzing(source_data: pl.DataFrame=None, data_symbol: str=None, data_phase: int=None, is_double: bool=None, is_sum: bool=None, symbol_id: int=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    探索数据关联关系\n",
    "    :param source_data: 原始数据\n",
    "    :param data_symbol: 数据标记\n",
    "    :param data_phase: 数据阶段\n",
    "    :param is_double: 是否成对分析\n",
    "    :param is_sum: 指标是否累积\n",
    "    :param symbol_id: 交易品种ID\n",
    "    :return: 无\n",
    "    \"\"\"\n",
    "    sub_type_dict = {\"features\": \"数据特征\", \"responders\": \"交易指标\", \"responder&responders\": \"预测交易指标&辅助交易指标\", \"responder&features\": \"预测交易指标&数据特征\"}\n",
    "    plt_name = f\"{str(symbol_id) + '-' if symbol_id is not None else ''}{'全局' if data_phase==1 else '局部' if data_phase==2 else ''}{'累积' + sub_type_dict[data_symbol] if is_sum else sub_type_dict[data_symbol]}间的{'成对' if is_double else '成组'}相关性分析\"\n",
    "    is_large_plt = False if source_data.shape[1] <= 18 else True\n",
    "    data_cols = list(source_data.columns)\n",
    "    if global_params[\"predict_responder\"] in data_cols:\n",
    "        data_cols.remove(global_params[\"predict_responder\"])\n",
    "        data_cols.append(global_params[\"predict_responder\"])\n",
    "    source_data = source_data[data_cols]\n",
    "    correlation_matrix, stronger_correlation_factor = correlation_factor_extracting(source_data=source_data, max_corr_param=0.8)\n",
    "    source_data = source_data[stronger_correlation_factor]\n",
    "    try:\n",
    "        if not is_double:\n",
    "            plt.figure(figsize=(12, 12))\n",
    "            sns.heatmap(correlation_matrix, square=True, cmap=\"coolwarm\", alpha =0.5, vmin=-1, vmax=1, center= 0, linewidths=0.5, linecolor=\"white\", annot=True if not is_large_plt else False, fmt=\".3f\")\n",
    "            plt.xticks(fontsize=9)\n",
    "            plt.yticks(fontsize=9)\n",
    "            if not is_large_plt:\n",
    "                plt.xticks(ticks=range(len(data_cols)), labels=data_cols, rotation=45, va=\"top\")\n",
    "                plt.yticks(ticks=range(len(data_cols)), labels=data_cols, rotation=0, ha=\"right\")\n",
    "            plt.xlabel(data_symbol, fontsize=12)\n",
    "            plt.ylabel(data_symbol, fontsize=12)\n",
    "            plt.title(plt_name, fontsize=14)\n",
    "        else:\n",
    "            plt_nums = source_data.shape[1] - 1\n",
    "            plt_col_nums = global_params[\"subplot_col_num\"]\n",
    "            plt_row_nums = math.ceil(plt_nums / plt_col_nums)\n",
    "            fig, axes = plt.subplots(nrows=plt_row_nums, ncols=plt_col_nums, figsize=(15, (plt_col_nums + 1) * plt_row_nums), squeeze=False)\n",
    "            plt.suptitle(plt_name, ha=\"center\", va=\"bottom\", fontsize=16, y=0.95 if data_symbol!=\"responder&features\" else 0.96)\n",
    "            for plt_idx in range(plt_col_nums * plt_row_nums):\n",
    "                row_idx = plt_idx // plt_col_nums\n",
    "                col_idx = plt_idx % plt_col_nums\n",
    "                if plt_idx < plt_nums:\n",
    "                    # 探索预测交易指标与第i列数据间的相关性\n",
    "                    col = source_data.columns[plt_idx]\n",
    "                    ax = axes[row_idx, col_idx]\n",
    "                    ax.grid(color=\"grey\")\n",
    "                    ax.set_xlabel(f\"{col}\", fontsize=10)\n",
    "                    ax.set_ylabel(f\"{global_params['predict_responder']}\", fontsize=10)\n",
    "                    ax.set_title(f\"{col}&{global_params['predict_responder']}\", fontsize=12)\n",
    "                    ax.hexbin(source_data[col], source_data[global_params['predict_responder']], gridsize=500, cmap=\"coolwarm\", bins=\"log\", alpha = 0.2)\n",
    "                else:\n",
    "                    axes[row_idx, col_idx].axis(\"off\")\n",
    "            fig.patch.set_linewidth(3)\n",
    "            fig.patch.set_edgecolor(\"#000000\")\n",
    "            fig.patch.set_facecolor(\"#eeeeee\")\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt_path = os.path.join(global_params[\"result_dir\"], f\"{plt_name}.png\")\n",
    "        plt.savefig(plt_path)\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        print(f\"{plt_name}绘制失败，原因：{traceback.print_exc()}\")\n",
    "    \n",
    "    return correlation_matrix"
   ],
   "id": "1b48d185e5cfd0f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 数据分布探索\n",
    "def distribution_exploring(source_data: pl.DataFrame=None, is_division: bool=None, data_phase: int=None, is_responder: bool=False, is_feature: bool=False, symbol_id: int=None):\n",
    "    \"\"\"\n",
    "    探索数据分布关系\n",
    "    :param source_data: 原始数据\n",
    "    :param is_division: 是否独立\n",
    "    :param data_phase: 数据阶段\n",
    "    :param is_responder: 是否为指标数据\n",
    "    :param is_feature: 是否为特征数据\n",
    "    :param symbol_id: 交易品种ID\n",
    "    :return: 无\n",
    "    \"\"\"\n",
    "    plt_name = f\"{symbol_id}{'-单一交易' if is_division and is_responder else '-不同交易' if not is_division else ''}{'全局' if data_phase==1 else '局部' if data_phase==2 else ''}{'-特征' if is_feature else '指标' if is_responder else ''}数据分布关系探索\"\n",
    "    correlation_matrix, stronger_correlation_factor = correlation_factor_extracting(source_data=source_data, max_corr_param=0.8)\n",
    "    source_data = source_data[stronger_correlation_factor]\n",
    "    try:\n",
    "        if not is_division:\n",
    "            plt.figure(figsize=(16, 6))\n",
    "            for col in source_data.columns:\n",
    "                if col == global_params[\"predict_responder\"]:\n",
    "                    plt.plot(range(source_data.shape[0]), source_data[col].cum_sum(), color=\"red\", linewidth=1.2)\n",
    "                else:\n",
    "                    plt.plot(range(source_data.shape[0]), source_data[col].cum_sum(), linewidth=1)\n",
    "                plt.legend(source_data.columns, fontsize=14)\n",
    "                plt.xticks(fontsize=12)\n",
    "                plt.yticks(fontsize=12)\n",
    "                plt.xlabel(\"时间\", fontsize=14)\n",
    "                plt.ylabel(\"交易指标值\", fontsize=14)\n",
    "                plt.title(plt_name, fontsize=16)\n",
    "        else:\n",
    "            plt_col_nums = global_params[\"subplot_col_num\"]\n",
    "            plt_row_nums = source_data.shape[1] if not is_feature else source_data.shape[1] - 1\n",
    "            fig, axes = plt.subplots(nrows=plt_row_nums, ncols=plt_col_nums, figsize=(15, (plt_col_nums + 1) * plt_row_nums), squeeze=False)\n",
    "            plt.suptitle(plt_name, ha=\"center\", va=\"bottom\", fontsize=16, y=0.96)\n",
    "            for plt_idx in range(plt_row_nums * plt_col_nums):\n",
    "                row_idx = plt_idx // plt_col_nums\n",
    "                col_idx = plt_idx % plt_col_nums\n",
    "                if is_responder:\n",
    "                    # 探索第i维的指标数据分布\n",
    "                    col = source_data.columns[row_idx]\n",
    "                    ax = axes[row_idx, col_idx]\n",
    "                    ax.grid(color=\"grey\")\n",
    "                    plt_color = \"blue\" if col != global_params[\"predict_responder\"] else \"red\"\n",
    "                    line_color = \"red\" if col != global_params[\"predict_responder\"] else \"blue\"\n",
    "                    if col_idx == 0:\n",
    "                        ax.set_ylim([-6, 6])\n",
    "                        ax.set_xlabel(\"时间\", fontsize=10)\n",
    "                        ax.set_ylabel(\"交易指标值\", fontsize=10)\n",
    "                        ax.plot(range(source_data.shape[0]), source_data[col], color=plt_color, linewidth=0.08)\n",
    "                    if col_idx == 1:\n",
    "                        ax.set_xlabel(\"时间\", fontsize=10)\n",
    "                        ax.set_ylabel(\"累积交易指标值\", fontsize=10)\n",
    "                        ax.plot(range(source_data.shape[0]), source_data[col].cum_sum(), color=plt_color, linewidth=0.8)\n",
    "                    else:\n",
    "                        ax.set_xlabel(\"交易指标值\", fontsize=10)\n",
    "                        ax.set_ylabel(\"交易指标值频度\", fontsize=10)\n",
    "                        ax.hist(source_data[col], bins=1000, color=plt_color, density=True, histtype=\"step\")\n",
    "                        ax.hist(source_data[col], bins=1000, color=\"lightgrey\", density=True)\n",
    "                    ax.axhline(0, color=line_color, linestyle=\"-\", linewidth=1)\n",
    "                    ax.set_title(f\"{col}-{'原始分布' if col_idx == 0 else '累积分布' if col_idx == 1 else '密度分布'}\", fontsize=12)\n",
    "                elif is_feature:\n",
    "                    # 探索第i维的特征数据分布\n",
    "                    col = source_data.columns[row_idx]\n",
    "                    ax = axes[row_idx, col_idx]\n",
    "                    ax.grid(color=\"grey\")\n",
    "                    if col_idx == 0:\n",
    "                        ax.set_xlabel(\"时间\", fontsize=10)\n",
    "                        ax.set_ylabel(\"特征值\", fontsize=10)\n",
    "                        ax.plot(range(source_data.shape[0]), source_data[col], color=\"blue\")\n",
    "                    if col_idx == 1:\n",
    "                        ax.set_xlabel(\"时间\", fontsize=10)\n",
    "                        ax.set_ylabel(\"累积特征值\", fontsize=10)\n",
    "                        ax.plot(range(source_data.shape[0]), source_data[col].cum_sum(), color=\"blue\")\n",
    "                    else:\n",
    "                        ax.set_xlabel(\"特征值\", fontsize=10)\n",
    "                        ax.set_ylabel(\"特征值频度\", fontsize=10)\n",
    "                        ax.hist(source_data[col], bins=1000, color=\"blue\", density=True, histtype=\"step\")\n",
    "                        ax.hist(source_data[col], bins=1000, color=\"lightgrey\", density=True)\n",
    "                    ax.axhline(0, color=\"red\", linestyle=\"-\", linewidth=1)\n",
    "                    ax.set_title(f\"{col}-{'原始分布' if col_idx == 0 else '累积分布' if col_idx == 1 else '密度分布'}\", fontsize=12)\n",
    "            fig.patch.set_linewidth(3)\n",
    "            fig.patch.set_edgecolor(\"#000000\")\n",
    "            fig.patch.set_facecolor(\"#eeeeee\")\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt_path = os.path.join(global_params[\"result_dir\"], f\"{plt_name}.png\")\n",
    "        plt.savefig(plt_path)\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        print(f\"{plt_name}绘制失败，原因：{traceback.print_exc()}\")"
   ],
   "id": "cdfcd9a13910154f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 分析交易指标相关性\n",
    "def responder_correlation_analyzing(sub_data: pl.DataFrame=None, correlation_phase: int=None, is_sum: bool=None, symbol_id: int=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    分析指定交易品种预测指标与其他交易指标间的相关性\n",
    "    :param sub_data: 交易品种对应的指标数据\n",
    "    :param correlation_phase: 相关分析阶段\n",
    "    :param is_sum: 指标数据是否累积\n",
    "    :param symbol_id: 交易品种ID\n",
    "    :return: 交易指标间的相关性矩阵\n",
    "    \"\"\"\n",
    "    # 获取交易指标列名\n",
    "    if not is_sum:\n",
    "        responder_cols = sorted([col for col in sub_data.columns if col.startswith(\"responder_\") and not \"_cumsum\" in col])\n",
    "        # 探索交易指标间的数据分布关系\n",
    "        distribution_exploring(source_data=sub_data[responder_cols], is_division=False, data_phase=correlation_phase, is_responder=True, symbol_id=symbol_id)\n",
    "        distribution_exploring(source_data=sub_data[responder_cols], is_division=True, data_phase=correlation_phase, is_responder=True, symbol_id=symbol_id)\n",
    "        # 探索交易指标间的数据相关性关系\n",
    "        correlation_analyzing(source_data=sub_data[responder_cols], data_symbol=\"responder&responders\", data_phase=correlation_phase, is_double=True, is_sum=False, symbol_id=symbol_id)\n",
    "        responder_responders_correlation_matrix = correlation_analyzing(source_data=sub_data[responder_cols], data_symbol=\"responder&responders\", data_phase=correlation_phase, is_double=False, is_sum=False, symbol_id=symbol_id)\n",
    "    else:\n",
    "        responder_cols = sorted([col for col in sub_data.columns if all([col.startswith(\"responder_\"), \"_cumsum\" in col]) or col == global_params[\"predict_responder\"]])\n",
    "        # 探索累积交易指标间的相关性关系\n",
    "        correlation_analyzing(source_data=sub_data[responder_cols], data_symbol=\"responder&responders\", data_phase=correlation_phase, is_double=True, is_sum=True, symbol_id=symbol_id)\n",
    "        responder_responders_correlation_matrix = correlation_analyzing(source_data=sub_data[responder_cols], data_symbol=\"responder&responders\", data_phase=correlation_phase, is_double=False, is_sum=True, symbol_id=symbol_id)\n",
    "    \n",
    "    return responder_responders_correlation_matrix"
   ],
   "id": "9fa7ce4cb1668e63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 分析指标特征相关性\n",
    "def feature_correlation_analyzing(sub_data: pl.DataFrame=None, correlation_phase: int=None, is_sum: bool=None, symbol_id: int=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    分析指定交易品种预测指标与数据特征间的相关性\n",
    "    :param correlation_phase: 相关分析阶段\n",
    "    :param sub_data: 交易品种对应的特征数据\n",
    "    :param is_sum: 指标数据是否累积\n",
    "    :param symbol_id: 交易品种ID\n",
    "    :return: 预测交易指标与数据特征间的相关性矩阵\n",
    "    \"\"\"\n",
    "    # 获取数据特征列名\n",
    "    if not is_sum:\n",
    "        feature_cols = sorted([col for col in sub_data.columns if all([col.startswith(\"feature_\"), not \"_cumsum\" in col]) or col == global_params[\"predict_responder\"]])\n",
    "        # 探索特征数据分布关系\n",
    "        distribution_exploring(source_data=sub_data[feature_cols], is_division=True, data_phase=correlation_phase, is_feature=True, symbol_id=symbol_id)\n",
    "        # 探索预测交易指标与数据特征间的相关性关系\n",
    "        correlation_analyzing(source_data=sub_data[feature_cols], data_symbol=\"responder&features\", data_phase=correlation_phase, is_double=True, is_sum=False, symbol_id=symbol_id)\n",
    "        responder_features_correlation_matrix = correlation_analyzing(source_data=sub_data[feature_cols], data_symbol=\"responder&features\", data_phase=correlation_phase, is_double=False, is_sum=False, symbol_id=symbol_id)\n",
    "    else:\n",
    "        feature_cols = sorted([col for col in sub_data.columns if all([col.startswith(\"feature_\"), \"_cumsum\" in col]) or col == global_params[\"predict_responder\"]])\n",
    "        # 探索预测交易指标与数据特征间的相关性关系\n",
    "        correlation_analyzing(source_data=sub_data[feature_cols], data_symbol=\"responder&features\", data_phase=correlation_phase, is_double=True, is_sum=True, symbol_id=symbol_id)\n",
    "        responder_features_correlation_matrix = correlation_analyzing(source_data=sub_data[feature_cols], data_symbol=\"responder&features\", data_phase=correlation_phase, is_double=False, is_sum=True, symbol_id=symbol_id)\n",
    "    \n",
    "    return responder_features_correlation_matrix"
   ],
   "id": "356a0260b3274a9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 截断对齐数据\n",
    "def data_truncating_aligning(source_data: pl.DataFrame=None, symbol_id: int=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    原始数据截断后对齐\n",
    "    :param source_data: 原始数据\n",
    "    :param symbol_id: 交易品种ID\n",
    "    :return: 截断后对齐的缺失数据\n",
    "    \"\"\"\n",
    "    def longest_subsequence_searching(date_ids: list=None):\n",
    "        \"\"\"\n",
    "        查找最长交易子序列\n",
    "        :param date_ids: 交易日期序列\n",
    "        :return: 最长交易子序列\n",
    "        \"\"\"\n",
    "        groups = []\n",
    "        for key, group in itertools.groupby(enumerate(date_ids), lambda x: x[1] - x[0]):\n",
    "            groups.append(list(map(lambda x: x[1], group)))\n",
    "        longest_trading_subsequence = max(groups, key=len)\n",
    "\n",
    "        return longest_trading_subsequence\n",
    "\n",
    "    # 规整时间索引\n",
    "    longest_subsequence = longest_subsequence_searching(date_ids=sorted(source_data[\"date_id\"].unique()))\n",
    "    start_date, end_date = min(longest_subsequence), max(longest_subsequence)\n",
    "    date_dtype, time_dtype = source_data[\"date_id\"].dtype, source_data[\"time_id\"].dtype\n",
    "    time_index_data = pl.DataFrame({\n",
    "        \"date_id\": pl.Series(np.arange(start_date, end_date + 1).repeat(source_data[\"time_id\"].max() + 1),\n",
    "                             dtype=date_dtype),\n",
    "        \"time_id\": pl.Series(list(range(global_params[\"symbol_day_sample\"][symbol_id])) * (end_date - start_date + 1),\n",
    "                             dtype=time_dtype)\n",
    "    })\n",
    "    source_data = time_index_data.join(source_data, on=[\"date_id\", \"time_id\"], how=\"left\")\n",
    "\n",
    "    return source_data"
   ],
   "id": "839f009654fa7652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 区分数据分布\n",
    "def data_category_recognizing(source_data: pl.DataFrame=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    根据峰度和偏度指标对数据密度分布情况对进行归类\n",
    "    1. 近似正态分布 —— 峰度和偏度指标适中\n",
    "    2. 近似均匀分布 —— 峰度较小且偏度较大\n",
    "    3. 未知数据分布 —— 峰度很大且偏度很小及其他情况\n",
    "    :param source_data: 原始数据\n",
    "    :return: 数据分布类别\n",
    "    \"\"\"\n",
    "    def col_data_categorizing(data_series: pl.Series=None) -> float:\n",
    "        \"\"\"\n",
    "        对单列数据进行数据分布归类\n",
    "        :param data_series: 单一数据列\n",
    "        :return: 数据分布类别\n",
    "        \"\"\"\n",
    "        # 临时处理序列空值\n",
    "        valued_data_series = data_series.drop_nans().drop_nulls()\n",
    "        fill_value = 0 if valued_data_series.is_empty() else valued_data_series.mean()\n",
    "        data_series = data_series.fill_null(fill_value).fill_nan(fill_value)\n",
    "        # 计算峰度和偏度指标\n",
    "        col_kurtosis = abs(data_series.kurtosis())\n",
    "        col_skewness = abs(data_series.skew())\n",
    "        if (2 <= col_kurtosis <= 20) and col_skewness <= 2:\n",
    "            col_data_category = 1.0\n",
    "        elif col_kurtosis < 2 and col_skewness <= 10:\n",
    "            col_data_category = 2.0\n",
    "        else:\n",
    "            col_data_category = 3.0\n",
    "        \n",
    "        return col_data_category\n",
    "    \n",
    "    distribution_category_dict = dict([(col_name, col_data_categorizing(data_series=source_data[col_name])) for col_name in source_data.columns])\n",
    "    \n",
    "    return pl.DataFrame(distribution_category_dict)"
   ],
   "id": "d9321853b84f51cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 标记异常数据\n",
    "def data_detecting(source_data: pl.DataFrame = None, density_category: pl.DataFrame = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    异常数据标记\n",
    "    :param source_data: 原始数据\n",
    "    :param density_category: 分布类别\n",
    "    :return: 填补后的完备数据\n",
    "    \"\"\"\n",
    "    def col_outlier_detecting(data_series: pl.Series=None, data_category: float=None, needing_cols: list=None) -> pl.Series:\n",
    "        \"\"\"\n",
    "        序列异常值标记\n",
    "        :param data_series: 原始数据序列\n",
    "        :param data_category: 数据分布类别\n",
    "        :param needing_cols: 待处理数据列\n",
    "        :return: 标记异常后的缺失序列\n",
    "        \"\"\"\n",
    "        print(f\"正在处理列：{data_series.name}\")\n",
    "        if data_series.name not in needing_cols:\n",
    "            return data_series\n",
    "        else:\n",
    "            # 标记空值索引\n",
    "            null_flag = data_series.is_in([np.nan, np.inf, -np.inf]) | data_series.is_null()\n",
    "            if data_category in [1.0, 3.0]:\n",
    "                # 基于Z-score方法对近正态分布异常值进行标记\n",
    "                mean_value = data_series.filter(~null_flag).mean()\n",
    "                std_value = data_series.filter(~null_flag).std()\n",
    "                z_scores = (data_series - mean_value) / std_value\n",
    "                null_flag |= (z_scores > global_params[\"z_score_threshold\"]) | (z_scores < -global_params[\"z_score_threshold\"])\n",
    "            elif data_category == 2.0:\n",
    "                # 基于孤立森林对近均匀分布异常值进行标记\n",
    "                iso_forest = IsolationForest(n_estimators=global_params[\"max_Iso_estimators\"], contamination=\"auto\", n_jobs=-1)\n",
    "                labels = iso_forest.fit_predict(data_series.filter(~null_flag).to_numpy().reshape(-1, 1))\n",
    "                \n",
    "                # 创建掩码标记异常值并置空\n",
    "                mask = labels == -1\n",
    "                nan_count, mask_index, mask_length = [0, 0, len(mask)]\n",
    "                for null_tag in null_flag:\n",
    "                    if null_tag:\n",
    "                        nan_count += 1\n",
    "                    else:\n",
    "                        null_flag[mask_index + nan_count] = mask[mask_index]\n",
    "                        mask_index += 1\n",
    "    \n",
    "            # 异常数据置空\n",
    "            for index in range(len(null_flag)):\n",
    "                if null_flag[index]:\n",
    "                    data_series[index] = np.nan\n",
    "    \n",
    "            return data_series\n",
    "    \n",
    "    # 遍历特征列进行异常数据标记\n",
    "    needing_cols = [col_name for col_name in source_data.columns if (col_name.startswith(\"feature_\") or col_name.startswith(\"responder_\")) and len(source_data[col_name].unique()) > 1]\n",
    "    source_data = source_data.select([col_outlier_detecting(data_series=source_data[col_name], data_category=density_category[col_name].item(), needing_cols=needing_cols) for col_name in source_data.columns])\n",
    "    \n",
    "    return source_data"
   ],
   "id": "a059c3513f0af0fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 填补缺失数据\n",
    "def data_filling(source_data: pl.DataFrame=None, missing_ratio_data: pl.DataFrame=None, is_predict_phase: bool=False) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    原始数据填补\n",
    "    :param source_data: 原始数据\n",
    "    :param missing_ratio_data: 数据缺失率\n",
    "    :param is_predict_phase: 是否预测阶段\n",
    "    :return: 填补后的完备数据\n",
    "    \"\"\"\n",
    "    # 填补列缺失数据\n",
    "    def col_null_filling(data_series: pl.Series = None, missing_ratio_data: pl.DataFrame=None) -> pl.Series:\n",
    "        \"\"\"\n",
    "        序列缺失值近邻填补\n",
    "        :param missing_ratio_data: 数据缺失率\n",
    "        :param data_series: 原始数据序列\n",
    "        :return: k近邻填充后的完备序列\n",
    "        \"\"\"\n",
    "        if not isinstance(data_series, pl.Series):\n",
    "           raise ValueError(\"data_series应为Polars Series类型\")\n",
    "        \n",
    "        if missing_ratio_data[data_series.name].item() == 0:\n",
    "            return data_series\n",
    "        else:\n",
    "            # 提取非空值索引和对应值\n",
    "            not_null_mask = (~data_series.is_nan()) & (~data_series.is_null())\n",
    "            x_known = np.arange(len(data_series))[not_null_mask].reshape(-1, 1)\n",
    "            y_known = data_series.filter(not_null_mask).to_numpy().reshape(-1, 1)\n",
    "            \n",
    "            # 基于非空值占比选择近邻数据点并训练KNN回归模型\n",
    "            n_samples = len(x_known)\n",
    "            if n_samples == 0:\n",
    "                return pl.Series(np.zeros(data_series.shape[0]))\n",
    "            elif n_samples  < data_series.shape[0] * 0.0001:\n",
    "                knn_neighbors_num = n_samples - 1\n",
    "            else:\n",
    "                knn_neighbors_num = 5\n",
    "            knn_regressor = KNeighborsRegressor(n_neighbors=knn_neighbors_num)\n",
    "            knn_regressor.fit(x_known, y_known.ravel())\n",
    "            \n",
    "            # 利用KNN回归模型填补缺失值\n",
    "            x_all = np.arange(len(data_series)).reshape(-1, 1)\n",
    "            filled_values = knn_regressor.predict(x_all)\n",
    "            \n",
    "            return pl.Series(filled_values).alias(data_series.name).fill_nan(0).fill_null(0)\n",
    "    \n",
    "    if is_predict_phase:\n",
    "        source_data = source_data.fill_nan(0).fill_null(0)\n",
    "    else:\n",
    "        # 遍历特征列进行缺失数据填补\n",
    "        source_data = source_data.select([col_null_filling(data_series=source_data[col_name], missing_ratio_data=missing_ratio_data) for col_name in source_data.columns])\n",
    "        \n",
    "    return source_data"
   ],
   "id": "4dc6bad7d9f83755",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 组合统计信息\n",
    "def statistic_info_combining(source_data: pl.DataFrame=None, density_category_description: pl.DataFrame=None):\n",
    "    \"\"\"\n",
    "    统计信息组合\n",
    "    :param source_data: 填补后的完备数据\n",
    "    :param density_category_description: 数据分布类别描述\n",
    "    :return: 数据统计信息\n",
    "    \"\"\"\n",
    "    source_data_description = source_data.describe()\n",
    "\n",
    "    def combine_col_info(col_category: float=None, col_name: str=None, statistic_description: pl.DataFrame=None):\n",
    "        \"\"\"\n",
    "        对列统计信息进行组合\n",
    "        :param col_category: 列数据分布类别\n",
    "        :param col_name: 数据列名\n",
    "        :param statistic_description: 数据统计信息\n",
    "        :return: 列统计信息\n",
    "        \"\"\"\n",
    "        if col_category == 2.0:\n",
    "            col_mean_value = statistic_description.filter(pl.col(\"statistic\") == \"mean\").select(col_name).item()\n",
    "            col_std_value = statistic_description.filter(pl.col(\"statistic\") == \"std\").select(col_name).item()\n",
    "            col_statistic_info = [col_category, col_mean_value, col_std_value]\n",
    "        else:\n",
    "            col_min_value = statistic_description.filter(pl.col(\"statistic\") == \"min\").select(col_name).item()\n",
    "            col_max_value = statistic_description.filter(pl.col(\"statistic\") == \"max\").select(col_name).item()\n",
    "            col_statistic_info = [col_category, col_min_value, col_max_value]\n",
    "\n",
    "        return col_statistic_info\n",
    "\n",
    "    # 对数据统计信息进行遍历更新\n",
    "    for col_name in source_data.columns:\n",
    "        col_category = density_category_description[col_name].item()\n",
    "        density_category_description = density_category_description.with_columns(pl.lit(combine_col_info(col_category, col_name, source_data_description)).alias(col_name))\n",
    "\n",
    "    return density_category_description"
   ],
   "id": "35e5f64908a2202b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 构造数据特征\n",
    "def feature_constructing(source_data: pl.DataFrame=None):\n",
    "    \"\"\"\n",
    "    数据特征构造\n",
    "    :param source_data: 原始数据\n",
    "    :return: 构造后的数据特征\n",
    "    \"\"\"\n",
    "    # 提取可变列名\n",
    "    not_fixed_cols = [col_name for col_name in source_data.columns if col_name.startswith(\"feature_\") or col_name.startswith(\"responder_\")]\n",
    "\n",
    "    # 构造累积特征\n",
    "    source_data = source_data.with_columns([pl.col(col_name).cum_sum().alias(f\"{col_name}_cumsum\") for col_name in not_fixed_cols])\n",
    "    \n",
    "    # 构造滞后特征\n",
    "    source_data = source_data.with_columns([pl.col(col_name).shift(1).alias(f\"{col_name}_time_lagging_1\") for col_name in not_fixed_cols])\n",
    "    source_data = source_data.with_columns([pl.col(col_name).shift(global_params[\"symbol_day_sample\"][symbol_id]).alias(f\"{col_name}_date_lagging_1\") for col_name in not_fixed_cols])\n",
    "\n",
    "    return source_data"
   ],
   "id": "84c40500021dbb9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 原始数据探索\n",
    "def training_data_exploring():\n",
    "    # 初始化分析结果变量\n",
    "    factor_name_setting = False\n",
    "    truncated_dates_result = pl.DataFrame({\"factor_name\": [\"start_date\", \"end_date\"]})\n",
    "    missing_description_result1, missing_description_result2, missing_description_result3, partial_density_description_result = [pl.DataFrame() for _ in range(4)]\n",
    "    entire_individual_correlation_analyzing_result, partial_individual_correlation_analyzing_result, partial_cumsum_correlation_analyzing_result = [pl.DataFrame() for _ in range(3)]\n",
    "\n",
    "    # 遍历交易品种进行数据探索\n",
    "    for symbol_id in global_params[\"symbol_ids\"]:\n",
    "        print(f\"交易品种-{symbol_id}-数据探索开始\")\n",
    "\n",
    "        # 抽取原始数据\n",
    "        current_training_data = data_extracting(symbol_id=symbol_id)\n",
    "\n",
    "        # 设置分析结果矩阵的因子名称\n",
    "        if not factor_name_setting:\n",
    "            entire_factor_name = pl.DataFrame({\"factor_name\": current_training_data.columns})\n",
    "            missing_description_result1 = missing_description_result1.with_columns(entire_factor_name.select(\"factor_name\"))\n",
    "            missing_description_result2 = missing_description_result2.with_columns(entire_factor_name.select(\"factor_name\"))\n",
    "            missing_description_result3 = missing_description_result3.with_columns(entire_factor_name.select(\"factor_name\"))\n",
    "            partial_density_description_result = partial_density_description_result.with_columns(\n",
    "                entire_factor_name.select(\"factor_name\"))\n",
    "\n",
    "            # 定义特征因子名称\n",
    "            factor_name = [[f\"{col_name}\", f\"{col_name}_cumsum\", f\"{col_name}_time_id_lagging_1\", f\"{col_name}_date_id_lagging_1\"] for col_name in current_training_data.columns if any([col_name.startswith(\"feature_\"), col_name.startswith(\"responder_\")])]\n",
    "            factor_name = sorted([col_name for sub_partial_factor in factor_name for col_name in sub_partial_factor])\n",
    "\n",
    "            # 定义全局独立特征响应变量名称\n",
    "            partial_factor_name1 = [col_name for col_name in factor_name if all([col_name.startswith(\"feature_\") or (col_name.startswith(\"responder_\") and col_name != global_params[\"predict_responder\"]), \"cumsum\" not in col_name, \"time_id_lagging_1\" not in col_name, \"date_id_lagging_1\" not in col_name])]\n",
    "            correlation_factor_name = pl.DataFrame({\"factor_name\": partial_factor_name1})\n",
    "            entire_individual_correlation_analyzing_result = entire_individual_correlation_analyzing_result.with_columns(correlation_factor_name.select(\"factor_name\"))\n",
    "\n",
    "            # 定义截断独立特征响应变量名称\n",
    "            partial_factor_name2 = [col_name for col_name in factor_name if \"cumsum\" not in col_name and col_name != global_params[\"predict_responder\"]]\n",
    "            correlation_factor_name = pl.DataFrame({\"factor_name\": partial_factor_name2})\n",
    "            partial_individual_correlation_analyzing_result = partial_individual_correlation_analyzing_result.with_columns(correlation_factor_name.select(\"factor_name\"))\n",
    "\n",
    "            # 定义截断累积特征响应变量名称\n",
    "            partial_factor_name3 = [col_name for col_name in factor_name if \"cumsum\" in col_name]\n",
    "            correlation_factor_name = pl.DataFrame({\"factor_name\": partial_factor_name3})\n",
    "            partial_cumsum_correlation_analyzing_result = partial_cumsum_correlation_analyzing_result.with_columns(correlation_factor_name.select(\"factor_name\"))\n",
    "\n",
    "        factor_name_setting = True\n",
    "\n",
    "        # 源数据探索—缺失率计算\n",
    "        missing_description = missing_ratio_computing(source_data=current_training_data, missing_phase=1, symbol_id=symbol_id).fill_nan(0).fill_null(0)\n",
    "\n",
    "        # 源数据探索—指标关联分析\n",
    "        responders_correlation_matrix = responder_correlation_analyzing(sub_data=current_training_data, correlation_phase=1, is_sum=False, symbol_id=symbol_id).fill_nan(0)\n",
    "        individual_responders_correlation_data = responders_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "\n",
    "        # 源数据探索—特征关联分析\n",
    "        features_correlation_matrix = feature_correlation_analyzing(sub_data=current_training_data, correlation_phase=1, is_sum=False, symbol_id=symbol_id).fill_nan(0)\n",
    "        individual_features_correlation_data = features_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "\n",
    "        # 源数据预处理—截断对齐\n",
    "        truncated_training_data = data_truncating_aligning(source_data=current_training_data)\n",
    "\n",
    "        # 源数据预处理—缺失率计算\n",
    "        truncated_missing_description = missing_ratio_computing(source_data=truncated_training_data, missing_phase=2, symbol_id=symbol_id)\n",
    "\n",
    "        # 源数据预处理—分布划分\n",
    "        density_category_description = data_category_recognizing(source_data=truncated_training_data)\n",
    "\n",
    "        # 源数据预处理—异常标记\n",
    "        detected_training_data = data_detecting(source_data=truncated_training_data, density_category=density_category_description)\n",
    "\n",
    "        # 源数据预处理—缺失率计算\n",
    "        detected_missing_description = missing_ratio_computing(source_data=detected_training_data, missing_phase=3, symbol_id=symbol_id)\n",
    "\n",
    "        # 源数据预处理—缺失填补\n",
    "        filled_training_data = data_filling(source_data=detected_training_data, missing_ratio_data=detected_missing_description, is_predict_phase=False)\n",
    "\n",
    "        # 源数据预处理—统计组合\n",
    "        density_category_description = statistic_info_combining(source_data=filled_training_data, density_category_description=density_category_description)\n",
    "\n",
    "        # 源数据预处理—特征构造\n",
    "        constructed_training_data = feature_constructing(source_data=filled_training_data).drop_nans().drop_nulls()\n",
    "        constructed_training_data.write_parquet(os.path.join(global_params[\"result_dir\"], f\"交易品种-{symbol_id}-的数据特征.parquet\"))\n",
    "\n",
    "        # 源数据探索—独立指标关联分析\n",
    "        truncated_individual_responders_correlation_matrix = responder_correlation_analyzing(sub_data=constructed_training_data,correlation_phase=2, is_sum=False,symbol_id=symbol_id).fill_nan(0)\n",
    "        partial_individual_responders_correlation_data = truncated_individual_responders_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "\n",
    "        # 源数据探索—累积指标关联分析\n",
    "        truncated_cumsum_responders_correlation_matrix = responder_correlation_analyzing(sub_data=constructed_training_data, correlation_phase=2, is_sum=True, symbol_id=symbol_id).fill_nan(0)\n",
    "        partial_cumsum_responders_correlation_data = truncated_cumsum_responders_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "\n",
    "        # 源数据探索—独立特征关联分析\n",
    "        truncated_individual_features_correlation_matrix = feature_correlation_analyzing(sub_data=constructed_training_data, correlation_phase=2, is_sum=False, symbol_id=symbol_id).fill_nan(0)\n",
    "        partial_individual_features_correlation_data = truncated_individual_features_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "\n",
    "        # 源数据探索—累积特征关联分析\n",
    "        truncated_cumsum_features_correlation_matrix = feature_correlation_analyzing(sub_data=constructed_training_data, correlation_phase=2, is_sum=True, symbol_id=symbol_id).fill_nan(0)\n",
    "        partial_cumsum_features_correlation_data = truncated_cumsum_features_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "\n",
    "        # 记录数据分析结果\n",
    "        truncated_dates_result = truncated_dates_result.with_columns(pl.Series([constructed_training_data[\"date_id\"].min(), constructed_training_data[\"date_id\"].max()]).alias(f\"symbol_id_{symbol_id}\"))\n",
    "        missing_ratio_data1 = missing_description.select(pl.concat_list(pl.all()).alias(f\"symbol_id_{symbol_id}\")).explode(f\"symbol_id_{symbol_id}\")\n",
    "        missing_description_result1 = missing_description_result1.with_columns([missing_ratio_data1[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "        missing_ratio_data2 = truncated_missing_description.select(pl.concat_list(pl.all()).alias(f\"symbol_id_{symbol_id}\")).explode(f\"symbol_id_{symbol_id}\")\n",
    "        missing_description_result2 = missing_description_result2.with_columns([missing_ratio_data2[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "        missing_ratio_data3 = detected_missing_description.select(pl.concat_list(pl.all()).alias(f\"symbol_id_{symbol_id}\")).explode(f\"symbol_id_{symbol_id}\")\n",
    "        missing_description_result3 = missing_description_result3.with_columns([missing_ratio_data3[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "        density_category_data = density_category_description.select(pl.Series(density_category_description.to_dicts()[0].values()).alias(f\"symbol_id_{symbol_id}\"))\n",
    "        partial_density_description_result = partial_density_description_result.with_columns([density_category_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "        entire_individual_correlation_data = pl.concat([individual_features_correlation_data, individual_responders_correlation_data], how=\"vertical\")\n",
    "        entire_individual_correlation_analyzing_result = entire_individual_correlation_analyzing_result.with_columns([entire_individual_correlation_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "        truncated_individual_correlation_data = pl.concat([partial_individual_features_correlation_data, partial_individual_responders_correlation_data], how=\"vertical\")\n",
    "        partial_individual_correlation_analyzing_result = partial_individual_correlation_analyzing_result.with_columns([truncated_individual_correlation_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "        partial_cumsum_correlation_data = pl.concat([partial_cumsum_features_correlation_data, partial_cumsum_responders_correlation_data], how=\"vertical\")\n",
    "        partial_cumsum_correlation_analyzing_result = partial_cumsum_correlation_analyzing_result.with_columns([partial_cumsum_correlation_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "        print(f\"交易品种-{symbol_id}-数据探索完成\")\n",
    "        del current_training_data\n",
    "        del truncated_training_data\n",
    "        del constructed_training_data\n",
    "\n",
    "    # 存储数据分析结果\n",
    "    with pd.ExcelWriter(path=os.path.join(global_params[\"result_dir\"], \"数据分析结果.xlsx\"), engine=\"openpyxl\") as writer:\n",
    "        truncated_dates_result.to_pandas().to_excel(writer, sheet_name=\"截断日期区间\", index=False)\n",
    "        missing_description_result1.to_pandas().to_excel(writer, sheet_name=\"原始数据缺失率\", index=False)\n",
    "        missing_description_result2.to_pandas().to_excel(writer, sheet_name=\"截断对齐数据缺失率\", index=False)\n",
    "        missing_description_result3.to_pandas().to_excel(writer, sheet_name=\"异常标记数据缺失率\", index=False)\n",
    "        partial_density_description_result.to_pandas().to_excel(writer, sheet_name=\"截断对齐数据密度分类\", index=False)\n",
    "        entire_individual_correlation_analyzing_result.to_pandas().to_excel(writer, sheet_name=\"原始独立特征相关性\", index=False)\n",
    "        partial_individual_correlation_analyzing_result.to_pandas().to_excel(writer, sheet_name=\"截断独立特征相关性\", index=False)\n",
    "        partial_cumsum_correlation_analyzing_result.to_pandas().to_excel(writer, sheet_name=\"截断累积特征相关性\", index=False)"
   ],
   "id": "92fc01dbbbf72ce1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 初始化检验配置\n",
    "init_checking()\n",
    "data_file_gathering()\n",
    "# training_data_exploring()"
   ],
   "id": "e747090637704f08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 初始化分析结果变量\n",
    "factor_name_setting = False\n",
    "truncated_dates_result = pl.DataFrame({\"factor_name\": [\"start_date\", \"end_date\"]})\n",
    "missing_description_result1, missing_description_result2, missing_description_result3, partial_density_description_result = [pl.DataFrame() for _ in range(4)]\n",
    "entire_individual_correlation_analyzing_result, partial_individual_correlation_analyzing_result, partial_cumsum_correlation_analyzing_result = [pl.DataFrame() for _ in range(3)]\n",
    "\n",
    "# 遍历交易品种进行数据探索\n",
    "symbol_id = 18\n",
    "print(f\"交易品种-{symbol_id}-数据探索开始\")\n",
    "# 抽取原始数据\n",
    "current_training_data = data_extracting(symbol_id=symbol_id)\n",
    "\n",
    "# 设置分析结果矩阵的因子名称\n",
    "if not factor_name_setting:\n",
    "    entire_factor_name = pl.DataFrame({\"factor_name\": current_training_data.columns})\n",
    "    missing_description_result1 = missing_description_result1.with_columns(entire_factor_name.select(\"factor_name\"))\n",
    "    missing_description_result2 = missing_description_result2.with_columns(entire_factor_name.select(\"factor_name\"))\n",
    "    missing_description_result3 = missing_description_result3.with_columns(entire_factor_name.select(\"factor_name\"))\n",
    "    partial_density_description_result = partial_density_description_result.with_columns(entire_factor_name.select(\"factor_name\"))\n",
    "\n",
    "    # 定义特征因子名称\n",
    "    factor_name = [[f\"{col_name}\", f\"{col_name}_cumsum\", f\"{col_name}_time_id_lagging_1\", f\"{col_name}_date_id_lagging_1\"] for col_name in current_training_data.columns if any([col_name.startswith(\"feature_\"), col_name.startswith(\"responder_\")])]\n",
    "    factor_name = sorted([col_name for sub_partial_factor in factor_name for col_name in sub_partial_factor])\n",
    "\n",
    "    # 定义全局独立特征响应变量名称\n",
    "    partial_factor_name1 = [col_name for col_name in factor_name if all([col_name.startswith(\"feature_\") or (col_name.startswith(\"responder_\") and col_name != global_params[\"predict_responder\"]), \"cumsum\" not in col_name, \"time_id_lagging_1\" not in col_name, \"date_id_lagging_1\" not in col_name])]\n",
    "    correlation_factor_name = pl.DataFrame({\"factor_name\": partial_factor_name1})\n",
    "    entire_individual_correlation_analyzing_result = entire_individual_correlation_analyzing_result.with_columns(correlation_factor_name.select(\"factor_name\"))\n",
    "\n",
    "    # 定义截断独立特征响应变量名称\n",
    "    partial_factor_name2 = [col_name for col_name in factor_name if \"cumsum\" not in col_name and col_name != global_params[\"predict_responder\"]]\n",
    "    correlation_factor_name = pl.DataFrame({\"factor_name\": partial_factor_name2})\n",
    "    partial_individual_correlation_analyzing_result = partial_individual_correlation_analyzing_result.with_columns(correlation_factor_name.select(\"factor_name\"))\n",
    "\n",
    "    # 定义截断累积特征响应变量名称\n",
    "    partial_factor_name3 = [col_name for col_name in factor_name if \"cumsum\" in col_name]\n",
    "    correlation_factor_name = pl.DataFrame({\"factor_name\": partial_factor_name3})\n",
    "    partial_cumsum_correlation_analyzing_result = partial_cumsum_correlation_analyzing_result.with_columns(correlation_factor_name.select(\"factor_name\"))\n",
    "\n",
    "    factor_name_setting = True"
   ],
   "id": "c112d2ab4e69251",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—统计描述\n",
    "current_training_data_description = current_training_data.describe()\n",
    "current_training_data_description"
   ],
   "id": "a1f0cd8678819aea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—缺失率计算\n",
    "missing_description = missing_ratio_computing(source_data=current_training_data, missing_phase=1, symbol_id=symbol_id).fill_nan(0).fill_null(0)\n",
    "missing_description"
   ],
   "id": "47d1e10bdf836abc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—指标关联分析\n",
    "responders_correlation_matrix = responder_correlation_analyzing(sub_data=current_training_data, correlation_phase=1, is_sum=False, symbol_id=symbol_id).fill_nan(0)\n",
    "individual_responders_correlation_data = responders_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "responders_correlation_matrix"
   ],
   "id": "1e6ae8d8b3eb2366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—特征关联分析\n",
    "features_correlation_matrix = feature_correlation_analyzing(sub_data=current_training_data, correlation_phase=1, is_sum=False, symbol_id=symbol_id).fill_nan(0)\n",
    "individual_features_correlation_data = features_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "features_correlation_matrix"
   ],
   "id": "c6f169668a168125",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—截断对齐\n",
    "truncated_training_data = data_truncating_aligning(source_data=current_training_data)\n",
    "truncated_training_data"
   ],
   "id": "753bf8d870058995",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—缺失率计算\n",
    "truncated_missing_description = missing_ratio_computing(source_data=truncated_training_data, missing_phase=2, symbol_id=symbol_id)\n",
    "truncated_missing_description"
   ],
   "id": "2edd96080c118715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—分布划分\n",
    "density_category_description = data_category_recognizing(source_data=truncated_training_data)\n",
    "density_category_description"
   ],
   "id": "6a0f3b57d8acc0bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—异常标记\n",
    "detected_training_data = data_detecting(source_data=truncated_training_data, density_category=density_category_description)\n",
    "detected_training_data"
   ],
   "id": "7928947d0e5d530c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—缺失率计算\n",
    "detected_missing_description = missing_ratio_computing(source_data=detected_training_data, missing_phase=3, symbol_id=symbol_id)\n",
    "detected_missing_description"
   ],
   "id": "753983a72191c798",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—缺失填补\n",
    "filled_training_data = data_filling(source_data=detected_training_data, missing_ratio_data=detected_missing_description, is_predict_phase=False)\n",
    "filled_training_data"
   ],
   "id": "ee5da21564d8e334",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—统计组合\n",
    "density_category_description = statistic_info_combining(source_data=filled_training_data, density_category_description=density_category_description)\n",
    "density_category_description"
   ],
   "id": "4e35ff9df118f2f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据预处理—特征构造\n",
    "constructed_training_data = feature_constructing(source_data=filled_training_data).drop_nans().drop_nulls()\n",
    "constructed_training_data.write_parquet(os.path.join(global_params[\"result_dir\"], f\"交易品种-{symbol_id}-的数据特征.parquet\"))\n",
    "constructed_training_data"
   ],
   "id": "cd2fa037d6cbfe02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—独立指标关联分析\n",
    "truncated_individual_responders_correlation_matrix = responder_correlation_analyzing(sub_data=constructed_training_data, correlation_phase=2, is_sum=False, symbol_id=symbol_id).fill_nan(0)\n",
    "partial_individual_responders_correlation_data = truncated_individual_responders_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "truncated_individual_responders_correlation_matrix"
   ],
   "id": "43b567a64e566958",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—累积指标关联分析\n",
    "truncated_cumsum_responders_correlation_matrix = responder_correlation_analyzing(sub_data=constructed_training_data, correlation_phase=2, is_sum=True, symbol_id=symbol_id).fill_nan(0)\n",
    "partial_cumsum_responders_correlation_data = truncated_cumsum_responders_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "truncated_cumsum_responders_correlation_matrix"
   ],
   "id": "502b22cd78f69080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—独立特征关联分析\n",
    "truncated_individual_features_correlation_matrix = feature_correlation_analyzing(sub_data=constructed_training_data, correlation_phase=2, is_sum=False, symbol_id=symbol_id).fill_nan(0)\n",
    "partial_individual_features_correlation_data = truncated_individual_features_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "truncated_individual_features_correlation_matrix"
   ],
   "id": "b7c301ab07e92edb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 源数据探索—累积特征关联分析\n",
    "truncated_cumsum_features_correlation_matrix = feature_correlation_analyzing(sub_data=constructed_training_data, correlation_phase=2, is_sum=True, symbol_id=symbol_id).fill_nan(0)\n",
    "partial_cumsum_features_correlation_data = truncated_cumsum_features_correlation_matrix.select(pl.col(global_params[\"predict_responder\"]).alias(f\"symbol_id_{symbol_id}\"))[:-1]\n",
    "truncated_cumsum_features_correlation_matrix"
   ],
   "id": "df08e6bf086847db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 记录数据分析结果\n",
    "truncated_dates_result = truncated_dates_result.with_columns(pl.Series([constructed_training_data[\"date_id\"].min(), constructed_training_data[\"date_id\"].max()]).alias(f\"symbol_id_{symbol_id}\"))\n",
    "\n",
    "missing_ratio_data1 = missing_description.select(pl.concat_list(pl.all()).alias(f\"symbol_id_{symbol_id}\")).explode(f\"symbol_id_{symbol_id}\")\n",
    "missing_description_result1 = missing_description_result1.with_columns([missing_ratio_data1[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "missing_ratio_data2 = truncated_missing_description.select(pl.concat_list(pl.all()).alias(f\"symbol_id_{symbol_id}\")).explode(f\"symbol_id_{symbol_id}\")\n",
    "missing_description_result2 = missing_description_result2.with_columns([missing_ratio_data2[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "missing_ratio_data3 = detected_missing_description.select(pl.concat_list(pl.all()).alias(f\"symbol_id_{symbol_id}\")).explode(f\"symbol_id_{symbol_id}\")\n",
    "missing_description_result3 = missing_description_result3.with_columns([missing_ratio_data3[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "density_category_data = density_category_description.select(pl.Series(density_category_description.to_dicts()[0].values()).alias(f\"symbol_id_{symbol_id}\"))\n",
    "partial_density_description_result = partial_density_description_result.with_columns([density_category_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "entire_individual_correlation_data = pl.concat([individual_features_correlation_data, individual_responders_correlation_data], how=\"vertical\")\n",
    "entire_individual_correlation_analyzing_result = entire_individual_correlation_analyzing_result.with_columns([entire_individual_correlation_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "truncated_individual_correlation_data = pl.concat([partial_individual_features_correlation_data, partial_individual_responders_correlation_data], how=\"vertical\")\n",
    "partial_individual_correlation_analyzing_result = partial_individual_correlation_analyzing_result.with_columns([truncated_individual_correlation_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "partial_cumsum_correlation_data = pl.concat([partial_cumsum_features_correlation_data, partial_cumsum_responders_correlation_data], how=\"vertical\")\n",
    "partial_cumsum_correlation_analyzing_result = partial_cumsum_correlation_analyzing_result.with_columns([partial_cumsum_correlation_data[f\"symbol_id_{symbol_id}\"].alias(f\"symbol_id_{symbol_id}\")])\n",
    "\n",
    "print(f\"交易品种-{symbol_id}-数据探索完成\")"
   ],
   "id": "73a273c9f7e6c088",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 存储数据分析结果\n",
    "with pd.ExcelWriter(path=os.path.join([global_params[\"result_dir\"], global_params[\"data_result_file1\"]]), engine=\"openpyxl\") as writer:\n",
    "    truncated_dates_result.to_pandas().to_excel(writer, sheet_name=\"截断日期区间\", index=False)\n",
    "    missing_description_result1.to_pandas().to_excel(writer, sheet_name=\"原始数据缺失率\", index=False)\n",
    "    missing_description_result2.to_pandas().to_excel(writer, sheet_name=\"截断对齐数据缺失率\", index=False)\n",
    "    missing_description_result3.to_pandas().to_excel(writer, sheet_name=\"异常标记数据缺失率\", index=False)\n",
    "    partial_density_description_result.to_pandas().to_excel(writer, sheet_name=\"截断对齐数据统计信息\", index=False)\n",
    "    entire_individual_correlation_analyzing_result.to_pandas().to_excel(writer, sheet_name=\"原始独立特征相关性\", index=False)\n",
    "    partial_individual_correlation_analyzing_result.to_pandas().to_excel(writer, sheet_name=\"截断独立特征相关性\", index=False)\n",
    "    partial_cumsum_correlation_analyzing_result.to_pandas().to_excel(writer, sheet_name=\"截断累积特征相关性\", index=False)"
   ],
   "id": "7c9da82fe1bdb2ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8692bb6b1440ad4e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
